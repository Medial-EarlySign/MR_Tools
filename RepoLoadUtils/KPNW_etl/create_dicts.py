import pandas as pdimport osfrom shutil import copy#MR_ROOT = '/opt/medial/tools/bin/'#sys.path.append(os.path.join(MR_ROOT, 'common'))from Configuration import Configurationfrom utils import fixOS, write_tsv, add_fisrt_line, replace_spacesfrom drugs_to_load import build_drug_mapfrom stage_to_load_files import build_diag_mapfrom NDC_to_ATC import get_atc_ndc_mapdef code_desc_to_dict_df(df, dc_start, stack_cols):    df = df.assign(defid=range(dc_start, dc_start + df.shape[0]))    stack_cols.append('defid')    to_stack = df[stack_cols].set_index('defid', drop=True)    dict_df = to_stack.stack().to_frame()    dict_df['defid'] = dict_df.index.get_level_values(0)    dict_df.rename({0: 'code'}, axis=1, inplace=True)    dict_df['def'] = 'DEF'    return dict_dfdef create_demo_dict():    demo_sigs = ['ETHNICITY', 'RACE', 'OCCUPATION', 'ZIP3']    cfg = Configuration()    work_folder = fixOS(cfg.work_path)    code_folder = fixOS(cfg.code_folder)    files_folder = os.path.join(work_folder, 'FinalSignals')    dict_path = os.path.join(work_folder, 'rep_configs', 'dicts')    dc_start = 1000    dict_file = 'dict.demo'    all_vals_df = pd.DataFrame()    for sig in demo_sigs:        sig_file = os.path.join(files_folder, sig)        df = pd.read_csv(sig_file, usecols=[2], names=['value'],dtype={'value': str}, sep='\t',  keep_default_na=False)        df.drop_duplicates(inplace=True)        all_vals_df = all_vals_df.append(df)    all_vals_df.drop_duplicates(inplace=True)    all_vals_df.dropna(inplace=True)    #all_vals_df['value'] = replace_spaces(all_vals_df['value'])    all_vals_df = all_vals_df.assign(defid=range(dc_start, dc_start + all_vals_df.shape[0]))    all_vals_df['def'] = 'DEF'    cols = ['def', 'defid', 'value']    if os.path.exists(os.path.join(dict_path, dict_file)):        os.remove(os.path.join(dict_path, dict_file))    write_tsv(all_vals_df[cols], dict_path, dict_file)    first_line = 'SECTION\t' + ','.join(demo_sigs) + '\n'    add_fisrt_line(first_line, os.path.join(dict_path, dict_file))def create_labs_dicts():    cfg = Configuration()    work_folder = fixOS(cfg.work_path)    code_folder = fixOS(cfg.code_folder)    files_folder = os.path.join(work_folder, 'FinalSignals')    load_files = os.listdir(files_folder)    dict_path = os.path.join(work_folder, 'rep_configs', 'dicts')    dc_start = 1000    dict_file = 'dict.labs'    kp_map = pd.read_csv(os.path.join(code_folder, 'kp_signal_map.csv'), sep='\t')    lab_chart_cond = ((kp_map['source'].str.contains('kpnwlabs')) & (kp_map['type'] == 'string'))    kp_cat_sigs = kp_map[lab_chart_cond]['signal'].tolist()    kp_cat_sigs = list(set(kp_cat_sigs))    all_vals_df = pd.DataFrame()    for sig in kp_cat_sigs:        sig_files = [x for x in load_files if x.startswith(sig)]        for f in sig_files:            sig_file = os.path.join(files_folder, f)            df = pd.read_csv(sig_file, usecols=[3], names=['value'], sep='\t', keep_default_na=False)            df.drop_duplicates(inplace=True)            all_vals_df = all_vals_df.append(df)    all_vals_df.drop_duplicates(inplace=True)    all_vals_df = all_vals_df[(all_vals_df['value'].notnull()) & (all_vals_df['value'].str != '')]    all_vals_df = all_vals_df.assign(defid=range(dc_start, dc_start + all_vals_df.shape[0]))    all_vals_df['def'] = 'DEF'    cols = ['def', 'defid', 'value']    write_tsv(all_vals_df[cols], dict_path, dict_file, mode='w')    first_line = 'SECTION\t' + ','.join(kp_cat_sigs) + '\n'    add_fisrt_line(first_line, os.path.join(dict_path, dict_file))def create_visit_adm_dicts():    signals = ['VISIT', 'ADMISSION']    cfg = Configuration()    work_folder = fixOS(cfg.work_path)    code_folder = fixOS(cfg.code_folder)    drg_file = os.path.join(code_folder, 'DRG-MC.txt')    drg_map = pd.read_csv(drg_file, sep='\t', names=['DRG_code', 'DRG_desc'], dtype={'DRG_code': str, 'DRG_desc': str})    drg_map['DRG_code'] = drg_map['DRG_code'].str.zfill(3)    drg_map = drg_map.set_index('DRG_code')['DRG_desc']    files_folder = os.path.join(work_folder, 'FinalSignals')    dict_path = os.path.join(work_folder, 'rep_configs', 'dicts')    dc_start = 5000    dict_file = 'dict.visits'    all_vals_df = pd.DataFrame()    for f in signals:        sig_file = os.path.join(files_folder, f)        col_ind = 3        if f == 'ADMISSION':            col_ind = 4        df = pd.read_csv(sig_file, usecols=[col_ind], names=['code'], sep='\t', keep_default_na=False)        df.drop_duplicates(inplace=True)        all_vals_df = all_vals_df.append(df)    all_vals_df.drop_duplicates(inplace=True)    all_vals_df = all_vals_df[(all_vals_df['code'].notnull()) & (all_vals_df['code'].str != '')]    hosp_type = all_vals_df['code'].apply(lambda x: x.split(':')[0]).drop_duplicates()    all_vals_df = all_vals_df['code'].append(hosp_type).to_frame()    all_vals_df = all_vals_df.assign(defid=range(dc_start, dc_start + all_vals_df.shape[0]))    all_vals_df['def'] = 'DEF'    # Get DRG dict    df = pd.read_csv(os.path.join(files_folder, 'ADMISSION'), usecols=[5], names=['value'], sep='\t', keep_default_na=False)    df.drop_duplicates(inplace=True)    df['DRG'] = df['value'].apply(lambda x: x.split(':')[1])    df['DRG_desc'] = df['DRG'].map(drg_map)    print(df[df['DRG_desc'].isnull()]['DRG'])    df['DRG_desc'] = replace_spaces(df['DRG_desc'])    #df['DRG_desc'] = df['value'] + ':' + df['DRG_desc']    dc_start = all_vals_df['defid'].max() + 10    drg_dict_df = code_desc_to_dict_df(df, dc_start, ['value', 'DRG_desc'])    def_vals_df = pd.concat([all_vals_df, drg_dict_df], sort=False)    cols = ['def', 'defid', 'code']    if os.path.exists(os.path.join(dict_path, dict_file)):        os.remove(os.path.join(dict_path, dict_file))    write_tsv(def_vals_df[cols], dict_path, dict_file)    first_line = 'SECTION\t' + ','.join(signals) + '\n'    add_fisrt_line(first_line, os.path.join(dict_path, dict_file))    all_vals_df['hosp_type'] = all_vals_df['code'].apply(lambda x: x.split(':')[0])    set_df = all_vals_df[all_vals_df['hosp_type'] != all_vals_df['code']]    set_df.loc[:, 'set'] = 'SET'    write_tsv(set_df[['set', 'hosp_type', 'code']], dict_path, dict_file)def create_behav_dict():    cfg = Configuration()    work_folder = fixOS(cfg.work_path)    code_folder = fixOS(cfg.code_folder)    files_folder = os.path.join(work_folder, 'FinalSignals')    load_files = os.listdir(files_folder)    dict_path = os.path.join(work_folder, 'rep_configs', 'dicts')    dc_start = 8000    dict_file = 'dict.behav'    kp_map = pd.read_csv(os.path.join(code_folder, 'kp_signal_map.csv'), sep='\t')    lab_chart_cond = ((kp_map['source'].str.contains('medial_flu_behav_char')) & (kp_map['type'] == 'string'))    kp_cat_sigs = kp_map[lab_chart_cond]['signal'].tolist()    all_vals_df = pd.DataFrame()    for sig in kp_cat_sigs:        sig_files = [x for x in load_files if x.startswith(sig)]        for f in sig_files:            sig_file = os.path.join(files_folder, f)            df = pd.read_csv(sig_file, usecols=[3], names=['value'], sep='\t', keep_default_na=False)            df.drop_duplicates(inplace=True)            all_vals_df = all_vals_df.append(df)    all_vals_df.drop_duplicates(inplace=True)    all_vals_df.dropna(inplace=True)    all_vals_df['value'] = replace_spaces(all_vals_df['value'].str.strip())    all_vals_df['value'] = all_vals_df['value'].str.replace('=', '').str.replace('"', '').str.replace('`', '')    all_vals_df = all_vals_df[(all_vals_df['value'].notnull()) & (all_vals_df['value'].str.strip() != '')]    all_vals_df.drop_duplicates(inplace=True)    all_vals_df = all_vals_df.assign(defid=range(dc_start, dc_start + all_vals_df.shape[0]))    all_vals_df['def'] = 'DEF'    cols = ['def', 'defid', 'value']    write_tsv(all_vals_df[cols], dict_path, dict_file, mode='w')    first_line = 'SECTION\t' + ','.join(kp_cat_sigs) + '\n'    add_fisrt_line(first_line, os.path.join(dict_path, dict_file))def read_ontology_dict(dict_file):    icd9_df = pd.read_csv(dict_file, sep='\t', encoding='utf-8', usecols=[1, 2], names=['defid', 'code'])    unstack = icd9_df.unstack()    return unstackdef create_diagnosis_dict():    signal = 'DIAGNOSIS'    code_pef = '_CODE:'    cfg = Configuration()    work_folder = fixOS(cfg.work_path)    onto_folder = fixOS(cfg.ontology_folder)    dict_path = os.path.join(work_folder, 'rep_configs', 'dicts')    dc_start = 10000    dict_file = 'dict.DIAGNOSIS'    dict_map_df = build_diag_map().reset_index()    dict_map_df.rename(columns={'diag_name': 'desc', 'diagid': 'code'}, inplace=True)    dict_df = code_desc_to_dict_df(dict_map_df, dc_start, ['code', 'desc'])    if os.path.exists(os.path.join(dict_path, dict_file)):        os.remove(os.path.join(dict_path, dict_file))    #write_tsv(dict_df[['def', 'defid', 'code']], dict_path, dict_file)    first_line = 'SECTION\t' + signal + '\n'    add_fisrt_line(first_line, os.path.join(dict_path, dict_file))    dict_map_df = dict_map_df.merge(dict_map_df['desc'].str.split(':', expand=True), left_index=True, right_index=True)    dict_map_df = dict_map_df[dict_map_df[0] != 'KP']    dict_map_df['icd_code'] = dict_map_df[0] + code_pef + dict_map_df[1].str.replace('.', '')    #read dicts to map    icd9_dict = os.path.join(onto_folder, 'ICD9', 'dicts', 'dict.icd9dx')    icd9_df = pd.read_csv(icd9_dict, sep='\t', usecols=[2], names=['code'])    icd9_df = icd9_df[icd9_df['code'].str.contains(code_pef)]    icd10_dict = os.path.join(onto_folder, 'ICD10', 'dicts', 'dict.icd10')    icd10_df = pd.read_csv(icd10_dict, sep='\t',  usecols=[2], names=['code'])    icd10_df = icd10_df[icd10_df['code'].str.contains(code_pef)]    icd_df = pd.concat([icd9_df, icd10_df])    icd_df = icd_df.merge(dict_map_df, how='left', left_on='code', right_on='icd_code')    icd_df = icd_df[icd_df['icd_code'].notnull()][['code_x', 'code_y']]    icd_df['set'] = 'SET'    set_file = 'dict.DIAGNOSIS_set'    if os.path.exists(os.path.join(dict_path, set_file)):        os.remove(os.path.join(dict_path, set_file))    write_tsv(icd_df[['set', 'code_x', 'code_y']], dict_path, set_file)    first_line = 'SECTION\t' + signal + '\n'    add_fisrt_line(first_line, os.path.join(dict_path, set_file))def copy_onto_files():    signal = 'DIAGNOSIS'    cfg = Configuration()    work_folder = fixOS(cfg.work_path)    onto_folder = fixOS(cfg.ontology_folder)    dict_path = os.path.join(work_folder, 'rep_configs', 'dicts')    first_line = 'SECTION\t' + signal + '\n'    # Copy ICD9 and ICD10 def set and map file    onto_files = [os.path.join(onto_folder, 'ICD9', 'dicts', 'dict.icd9dx'),                  os.path.join(onto_folder, 'ICD9', 'dicts', 'dict.set_icd9dx'),                  os.path.join(onto_folder, 'ICD10', 'dicts', 'dict.icd10'),                  os.path.join(onto_folder, 'ICD10', 'dicts', 'dict.set_icd10'),                  os.path.join(onto_folder, 'ICD9_TO_ICD10', 'dicts', 'dict.set_icd9_2_icd10'),                  os.path.join(onto_folder, 'ICD10_TO_ICD9', 'dicts', 'dict.set_icd10_2_icd9')]    for ont in onto_files:        copy(ont, dict_path)        add_fisrt_line(first_line, os.path.join(dict_path, os.path.basename(ont)))def create_diagnosis_dict_old():    signal = 'DIAGNOSIS'    cfg = Configuration()    work_folder = fixOS(cfg.work_path)    onto_folder = fixOS(cfg.ontology_folder)    code_folder = fixOS(cfg.code_folder)    # files_folder = os.path.join(work_folder, 'FinalSignals')    data_path = os.path.join(work_folder, 'data')    pat_diag_file = 'medial_flu_diagnosis.csv'    full_file = os.path.join(data_path, pat_diag_file)    dict_path = os.path.join(work_folder, 'rep_configs', 'dicts')    dc_start = 10000    dict_file = 'dict.DIAGNOSIS'    all_diags = pd.DataFrame()    cnt = 1    for kp_diag in pd.read_csv(full_file, sep='\t',usecols=[3, 4, 5], chunksize=5000000, iterator=True):        print('reading chunk ' + str(cnt))        kp_diag.drop_duplicates(inplace=True)        all_diags = all_diags.append(kp_diag)        all_diags.drop_duplicates(inplace=True)        print(' digs count = ' + str(all_diags.shape[0]))        cnt += 1        # break    all_diags = all_diags[all_diags['INDST_DX_CD'].notnull()]    all_diags['DX_NM'] = replace_spaces(all_diags['DX_NM'])    kp_diag['INDST_DX_CD'] = kp_diag['INDST_DX_CD'].str.replace(',', '.')    all_diags['nodots'] = all_diags['INDST_DX_CD'].str.replace('.', '')    #all_diags['INDST_DX_CD'] = all_diags['INDST_DX_CD'].str.replace('.', '')    cond1 = (all_diags['INDST_DX_TYP'].str.contains('ICD-10', na=False))    all_diags.loc[cond1, 'prefix'] = 'ICD10'    cond2 = (all_diags['INDST_DX_TYP'].str.contains('ICD-9', na=False))    all_diags.loc[cond2, 'prefix'] = 'ICD9'    cond3 = all_diags['INDST_DX_TYP'].isnull()    all_diags.loc[cond3, 'prefix'] = 'KP'    all_diags.rename(columns={'INDST_DX_CD': 'code', 'DX_NM': 'desc'}, inplace=True)    #all_diags['only_code'] = all_diags['code'] #TEMP    all_diags['desc'] = all_diags['prefix'] + '_DESC:' + all_diags['code'] + ':' + all_diags['desc']    all_diags['code'] = all_diags['prefix'] + '_CODE:' + all_diags['code']    #all_diags.loc[all_diags['prefix'] == 'KP',  'code'] = all_diags[all_diags['prefix'] == 'KP']['prefix'] + ':' + all_diags[all_diags['prefix'] == 'KP']['only_code'] #TEMP    all_diags['nodots'] = all_diags['prefix'] + '_CODE:' + all_diags['nodots']    lists = all_diags.groupby(['code', 'nodots'])['desc'].apply(list)    lists_df = pd.DataFrame(lists.values.tolist(), index=lists.index).reset_index()    #lists_df = lists_df.merge(all_diags[['code', 'nodots']], on='code', how='left')    dict_df = code_desc_to_dict_df(lists_df, dc_start, ['code', 'nodots', 0, 1, 2, 3, 4])    dict_df.drop_duplicates(inplace=True)    if os.path.exists(os.path.join(dict_path, dict_file)):        os.remove(os.path.join(dict_path, dict_file))    write_tsv(dict_df[['def', 'defid', 'code']], dict_path, dict_file)    first_line = 'SECTION\t' + signal + '\n'    add_fisrt_line(first_line, os.path.join(dict_path, dict_file))    icd9_dict = os.path.join(onto_folder, 'ICD9', 'dicts', 'dict.icd9dx')    icd9_df = pd.read_csv(icd9_dict, sep='\t', names=['def', 'defid', 'code'])    icd9_df = icd9_df.merge(dict_df[['defid', 'code']], on='code', how='left')    icd9_df = icd9_df[icd9_df['defid_y'].isnull()]    #matched_ids = icd9_df[icd9_df['defid_y'].notnull()]['defid_x'].unique()    #icd9_df = icd9_df[~(icd9_df['defid_x'].isin(matched_ids.tolist()))]    if os.path.exists(os.path.join(dict_path, 'dict.icd9')):        os.remove(os.path.join(dict_path, 'dict.icd9'))    write_tsv(icd9_df[['def', 'defid_x', 'code']], dict_path, 'dict.icd9')    add_fisrt_line(first_line, os.path.join(dict_path, 'dict.icd9'))    icd9_set_dict = os.path.join(onto_folder, 'ICD9', 'dicts', 'dict.set_icd9dx')    copy(icd9_set_dict, dict_path)    add_fisrt_line(first_line, os.path.join(dict_path, os.path.basename(icd9_set_dict)))    icd10_dict = os.path.join(onto_folder, 'ICD10', 'dicts', 'dict.icd10')    icd10_df = pd.read_csv(icd10_dict, sep='\t', names=['def', 'defid', 'code'])    icd10_df = icd10_df.merge(dict_df[['defid', 'code']], on='code', how='left')    icd10_df = icd10_df[icd10_df['defid_y'].isnull()]    #matched_ids = icd10_df[icd10_df['defid_y'].notnull()]['defid_x'].unique()    #icd10_df = icd10_df[(icd10_df['defid_x'].isin(matched_ids.tolist()))]    if os.path.exists(os.path.join(dict_path, 'dict.icd10')):        os.remove(os.path.join(dict_path, 'dict.icd10'))    write_tsv(icd10_df[['def', 'defid_x', 'code']], dict_path, 'dict.icd10')    add_fisrt_line(first_line, os.path.join(dict_path, 'dict.icd10'))    #print(icd10_df)    icd10_set_dict = os.path.join(onto_folder, 'ICD10', 'dicts', 'dict.set_icd10')    copy(icd10_set_dict, dict_path)    add_fisrt_line(first_line, os.path.join(dict_path, os.path.basename(icd10_set_dict)))    icd9_icd10_dict = os.path.join(onto_folder, 'ICD9_TO_ICD10', 'dicts', 'dict.set_icd9_2_icd10')    copy(icd9_icd10_dict, dict_path)    add_fisrt_line(first_line, os.path.join(dict_path, os.path.basename(icd9_icd10_dict)))'''def create_drug_dict():    signal = 'Drug'    cfg = Configuration()    work_folder = fixOS(cfg.work_path)    code_folder = fixOS(cfg.code_folder)    onto_folder = fixOS(cfg.ontology_folder)    dict_path = os.path.join(work_folder, 'rep_configs', 'dicts')    dc_start = 10000    dict_file = 'dict.Drug'    dict_df = build_drug_map().reset_index()    dict_df.rename(columns={'drug_name': 'desc', 'drugid': 'code'}, inplace=True)    dict_df['desc'] = dict_df['desc'].str.replace(' ', '_')    dict_df.drop_duplicates(inplace=True)    dict_df = code_desc_to_dict_df(dict_df, dc_start, ['code', 'desc'])    if os.path.exists(os.path.join(dict_path, dict_file)):        os.remove(os.path.join(dict_path, dict_file))    write_tsv(dict_df[['def', 'defid', 'code']], dict_path, dict_file)    first_line = 'SECTION\t' + signal + '\n'    add_fisrt_line(first_line, os.path.join(dict_path, dict_file))    # Creating SET    set_file = 'dict.Drug_set'    drug_map_file = 'mapping_drug_names_to_atc'    atc_map_file = os.path.join(code_folder, drug_map_file)    atc_map_df = pd.read_csv(atc_map_file, sep='\t', names=['map', 'drug_name', 'drug_code', 'code_list', 'atc_list'], header=0)    atc_map_df['atc_list'] = atc_map_df['atc_list'].apply(lambda x: eval(x))    lists_df = pd.DataFrame(atc_map_df['atc_list'].values.tolist(), index=atc_map_df['drug_code']).reset_index()    to_stack = lists_df.set_index('drug_code', drop=True)    set_df = to_stack.stack().to_frame()    set_df['inner'] = set_df.index.get_level_values(0)    set_df.rename({0: 'outer'}, axis=1, inplace=True)    set_df['set'] = 'SET'    if os.path.exists(os.path.join(dict_path, set_file)):        os.remove(os.path.join(dict_path, set_file))    write_tsv(set_df[['set', 'outer', 'inner']], dict_path, set_file)    first_line = 'SECTION\t' + signal + '\n'    add_fisrt_line(first_line, os.path.join(dict_path, set_file))    # copy the Ontology ATC dicts    to_copy = ['dict.atc_defs', 'dict.atc_sets']    for fl in to_copy:        atc_set_dict = os.path.join(onto_folder, 'ATC', 'dicts', fl)        copy(atc_set_dict, dict_path)        add_fisrt_line(first_line, os.path.join(dict_path, os.path.basename(atc_set_dict)))'''def ndc11_ndc9(ndc11):    if not ndc11.startswith('KP:') and '-' in ndc11:        #print(ndc11)        spl = ndc11.split('-')        s1 = str(int(spl[0])).zfill(4)        if s1[0] == '0' and len(s1) == 4:            s2 = str(int(spl[1])).zfill(4)        else:            s2 = str(int(spl[1])).zfill(3)        return s1 + '-' + s2    return ndc11def create_drug_dict():    signal = 'Drug'    cfg = Configuration()    work_folder = fixOS(cfg.work_path)    code_folder = fixOS(cfg.code_folder)    onto_folder = fixOS(cfg.ontology_folder)    dict_path = os.path.join(work_folder, 'rep_configs', 'dicts')    dc_start = 10000    dict_file = 'dict.Drug'    dict_df = build_drug_map().reset_index()    dict_df.rename(columns={'drug_name': 'desc', 'drugid': 'code'}, inplace=True)    dict_df['desc'] = replace_spaces(dict_df['desc'].str.upper())    dict_df.drop_duplicates(inplace=True)    dict_df['len'] = dict_df['desc'].str.len()    dict_df.sort_values(by=['code','len'], inplace=True)    dict_df.drop_duplicates('code', keep='last', inplace=True)    final_dict_df = code_desc_to_dict_df(dict_df, dc_start, ['code', 'desc'])    write_tsv(final_dict_df[['def', 'defid', 'code']], dict_path, dict_file, mode='w')    first_line = 'SECTION\t' + signal + '\n'    add_fisrt_line(first_line, os.path.join(dict_path, dict_file))    # Add NDC9 columns    kp_ncd_dict_df = dict_df[dict_df['code'].str.startswith('KP_NDC:')].copy()    kp_ncd_dict_df['NDC9'] = kp_ncd_dict_df['code'].str.replace('KP_NDC:', '')    kp_ncd_dict_df['NDC9'] = kp_ncd_dict_df['NDC9'].apply(lambda x: ndc11_ndc9(x))    # Read generic NDC dict    ndc_dict_file = os.path.join(onto_folder, 'NDC', 'dicts', 'dict.ndc_defs')    ndc_dict_full = pd.read_csv(ndc_dict_file, sep='\t', names=['def', 'defid', 'NDC9_full'])    ndc_dict_df = ndc_dict_full[ndc_dict_full['NDC9_full'].str.contains('NDC_CODE')].copy()    ndc_dict_df['NDC9'] = ndc_dict_df['NDC9_full'].str.replace('NDC_CODE:', '')    mrg = kp_ncd_dict_df.merge(ndc_dict_df, on='NDC9', how='left')    set_dict = mrg[mrg['defid'].notnull()][['NDC9_full', 'code']].copy()    # Read NDC dict    set_file = 'dict.Drug_set'    set_dict['set'] = 'SET'    write_tsv(set_dict[['set', 'NDC9_full', 'code']], dict_path, set_file, mode='w')    first_line = 'SECTION\t' + signal + '\n'    add_fisrt_line(first_line, os.path.join(dict_path, set_file))    # copy the Ontology ATC dicts    to_copy = [os.path.join(onto_folder, 'ATC', 'dicts', 'dict.atc_defs'),               os.path.join(onto_folder, 'ATC', 'dicts', 'dict.atc_sets'),               os.path.join(onto_folder, 'NDC', 'dicts', 'dict.atc_ndc_set'),               os.path.join(onto_folder, 'NDC', 'dicts', 'dict.ndc_defs')]    for fl in to_copy:        copy(fl, dict_path)        add_fisrt_line(first_line, os.path.join(dict_path, os.path.basename(fl)))def create_vaccination_dict():    signal = 'Vaccination'    cfg = Configuration()    work_folder = fixOS(cfg.work_path)    code_folder = fixOS(cfg.code_folder)    dict_path = os.path.join(work_folder, 'rep_configs', 'dicts')    dc_start = 1001    dict_file = 'dict.Vaccination'    code_name_file = os.path.join(code_folder, 'CVX_IMMUNZTN_NAME.tsv')    code_name_map = pd.read_csv(code_name_file, sep='\t')    code_name_map = code_name_map.append({'IMM_CVX_CODE': 0}, ignore_index=True)    code_name_map['IMMUNZATN_NAME'] = code_name_map['IMMUNZATN_NAME'].str.replace(' ', '_').str.replace(',', '_')    code_name_map['IMM_CVX_CODE'] = 'CVX_CODE:' + code_name_map['IMM_CVX_CODE'].astype(int).astype(str)    code_map = code_name_map.groupby('IMM_CVX_CODE')['IMMUNZATN_NAME'].apply(list)    code_map = pd.DataFrame(code_map.values.tolist(), index=code_map.index).reset_index()    dict_df = code_desc_to_dict_df(code_map, dc_start, code_map.columns.tolist())    if os.path.exists(os.path.join(dict_path, dict_file)):        os.remove(os.path.join(dict_path, dict_file))    write_tsv(dict_df[['def', 'defid', 'code']], dict_path, dict_file)    first_line = 'SECTION\t' + signal + '\n'    add_fisrt_line(first_line, os.path.join(dict_path, dict_file))def create_smoking_dict():    signal = 'Smoking_Status'    cfg = Configuration()    work_folder = fixOS(cfg.work_path)    dict_path = os.path.join(work_folder, 'rep_configs', 'dicts')    dict_file = 'dict.Smoking_Status'    dict1 = {0: 'Never', 1: 'Passive', 2: 'Former', 3: 'Current'}    df = pd.Series(dict1).reset_index()    df['def'] = 'DEF'    if os.path.exists(os.path.join(dict_path, dict_file)):        os.remove(os.path.join(dict_path, dict_file))    write_tsv(df[['def', 'index', 0]], dict_path, dict_file)    first_line = 'SECTION\t' + signal + '\n'    add_fisrt_line(first_line, os.path.join(dict_path, dict_file))def create_tier_dict():    signals = ['Vaccination_flu', 'Complications', 'FLU_REG']    cfg = Configuration()    work_folder = fixOS(cfg.work_path)    dict_path = os.path.join(work_folder, 'rep_configs', 'dicts')    dict_file = 'dict.tiers'    dict1 = {1: '1', 2: '2', 3: '3'}    df = pd.Series(dict1).reset_index()    df['def'] = 'DEF'    if os.path.exists(os.path.join(dict_path, dict_file)):        os.remove(os.path.join(dict_path, dict_file))    write_tsv(df[['def', 'index', 0]], dict_path, dict_file)    first_line = 'SECTION\t' + ','.join(signals) + '\n'    add_fisrt_line(first_line, os.path.join(dict_path, dict_file))def get_kp_drugs():    dict_df = build_drug_map().reset_index()    dict_df.rename(columns={'drug_name': 'desc', 'drugid': 'code'}, inplace=True)    kp_drugs_df = dict_df[dict_df['code'].str.startswith('KP:')].copy()    return kp_drugs_dfdef get_missing_ndcs(cfg):    onto_folder = fixOS(cfg.ontology_folder)    dict_df = build_drug_map().reset_index()    dict_df.rename(columns={'drug_name': 'desc', 'drugid': 'code'}, inplace=True)    dict_df['desc'] = replace_spaces(dict_df['desc'].str.upper())    #dict_df = dict_df[~dict_df['desc'].astype(str).str.contains('WALMART')]    dict_df.drop_duplicates(inplace=True)    #dict_df['len'] = dict_df['desc'].str.len()    #dict_df.sort_values(by=['code', 'len'], inplace=True, na_position='first')    #dict_df.drop_duplicates('code', keep='last', inplace=True)    kp_ncd_dict_df = dict_df[dict_df['code'].str.startswith('KP_NDC:')].copy()    kp_ncd_dict_df['NDC9'] = kp_ncd_dict_df['code'].str.replace('KP_NDC:', '')    kp_ncd_dict_df['NDC9'] = kp_ncd_dict_df['NDC9'].apply(lambda x: 'NDC_CODE:'+ndc11_ndc9(x))    ndc_dict_file = os.path.join(onto_folder, 'NDC', 'dicts', 'dict.ndc_defs')    ndc_dict_full = pd.read_csv(ndc_dict_file, sep='\t', skiprows=1, names=['def', 'defid', 'code'])    ndc_df = ndc_dict_full[ndc_dict_full['code'].str.contains('NDC_CODE:')].copy()    mrg1 = kp_ncd_dict_df.merge(ndc_df, how='left', left_on='NDC9', right_on='code')    return mrg1[mrg1['defid'].isnull()][['desc', 'NDC9']].copy()def create_drug_dict_with_atc_map():    signal = 'Drug'    first_line = 'SECTION\t' + signal + '\n'    cfg = Configuration()    work_folder = fixOS(cfg.work_path)    onto_folder = fixOS(cfg.ontology_folder)    dict_path = os.path.join(work_folder, 'rep_configs', 'dicts')    # Build basic dict from source values    dc_start = 10000    dict_file = 'dict.Drug'    dict_df = build_drug_map().reset_index()    dict_df.rename(columns={'drug_name': 'desc', 'drugid': 'code'}, inplace=True)    dict_df['len'] = dict_df['desc'].str.len()    dict_df.sort_values(by=['code', 'len'], inplace=True, na_position='first')    dict_df.drop_duplicates('code', keep='last', inplace=True)    final_dict_df = code_desc_to_dict_df(dict_df, dc_start, ['code', 'desc'])    write_tsv(final_dict_df[['def', 'defid', 'code']], dict_path, dict_file, mode='w')    add_fisrt_line(first_line, os.path.join(dict_path, dict_file))    # Add NDC9 columns    kp_ncd_dict_df = dict_df[dict_df['code'].str.startswith('KP_NDC:')].copy()    kp_ncd_dict_df['NDC9'] = kp_ncd_dict_df['code'].str.replace('KP_NDC:', '')    kp_ncd_dict_df['NDC9'] = kp_ncd_dict_df['NDC9'].apply(lambda x: ndc11_ndc9(x))    # Copy generic dicts    to_copy = [os.path.join(onto_folder, 'ATC', 'dicts', 'dict.atc_defs'),               os.path.join(onto_folder, 'ATC', 'dicts', 'dict.atc_sets'),               os.path.join(onto_folder, 'NDC', 'dicts', 'dict.atc_ndc_set'),               os.path.join(onto_folder, 'NDC', 'dicts', 'dict.ndc_defs')]    for fl in to_copy:        copy(fl, dict_path)        add_fisrt_line(first_line, os.path.join(dict_path, os.path.basename(fl)))    # Add NDCs with description found in KP and not in the FDA product.txt file    missing_ndcs = get_missing_ndcs(cfg)    # in some common cases the get_missing_ndcs peeks the wrong option, fixing...    missing_ndcs.loc[missing_ndcs['NDC9'] == 'NDC_CODE:49999-908', 'desc'] = 'ALBUTEROL'    missing_ndcs.loc[missing_ndcs['NDC9'] == 'NDC_CODE:10939-081', 'desc'] = 'FAMOTIDINE'    missing_ndcs.loc[missing_ndcs['NDC9'] == 'NDC_CODE:10939-156', 'desc'] = 'CETIRIZINE'    missing_ndcs.loc[missing_ndcs['NDC9'] == 'NDC_CODE:54569-5605', 'desc'] = 'INSULINS'    missing_ndcs.loc[missing_ndcs['NDC9'] == 'NDC_CODE:54569-2318', 'desc'] = 'INSULINS'    missing_ndcs['desc'] = missing_ndcs['desc'].str.replace('FLU_VACCINE', 'INFLUENZA VACCINES')    to_def_dict = missing_ndcs.drop_duplicates('NDC9')    to_def_dict['desc'] = to_def_dict['NDC9'].str.replace('NDC_CODE:', '') + ':' + to_def_dict['desc']    dc_start = 450000    miss_dict = code_desc_to_dict_df(to_def_dict, dc_start, ['NDC9', 'desc'])    write_tsv(miss_dict[['def', 'defid', 'code']], dict_path,  'dict.ndc_defs', mode='a')    # Read extended (with values found only in KP) NDC dict    ndc_dict_file = os.path.join(dict_path, 'dict.ndc_defs')    ndc_dict_full = pd.read_csv(ndc_dict_file, sep='\t', names=['def', 'defid', 'NDC9_full'], skiprows=1)    ndc_dict_df = ndc_dict_full[ndc_dict_full['NDC9_full'].str.contains('NDC_CODE')].copy()    ndc_dict_df['NDC9'] = ndc_dict_df['NDC9_full'].str.replace('NDC_CODE:', '')    # Add set for extended NDCs    mrg = kp_ncd_dict_df.merge(ndc_dict_df, on='NDC9', how='left')    set_dict = mrg[mrg['defid'].notnull()][['NDC9_full', 'code']].copy()    set_file = 'dict.Drug_set'    set_dict['set'] = 'SET'    write_tsv(set_dict[['set', 'NDC9_full', 'code']], dict_path, set_file, mode='w')    first_line = 'SECTION\t' + signal + '\n'    add_fisrt_line(first_line, os.path.join(dict_path, set_file))    # Try to map to ATC (same as NDC to ATC mapping is done)    missing_ndcs['SUBSTANCENAME'] = missing_ndcs['desc'].str.replace('_', ';').astype(str)    missing_ndcs.rename(columns={'NDC9': 'PRODUCTNDC'}, inplace=True)    #to_set_dict = missing_ndcs.copy()    kp_ndc_set = get_atc_ndc_map(missing_ndcs[['PRODUCTNDC', 'SUBSTANCENAME']], onto_folder)    set_file = 'dict.atc_ndc_set'    kp_ndc_set['set'] = 'SET'    kp_ndc_set.drop_duplicates(['set', 'atc', 'PRODUCTNDC'], inplace=True)    write_tsv(kp_ndc_set[['set', 'atc', 'PRODUCTNDC']], dict_path, set_file, mode='a')    # Try to map drugs with no NDC to ATC    kp_drugs = get_kp_drugs()    kp_drugs['desc'] = kp_drugs['desc'].str.replace('FLU_VACCINE', 'INFLUENZA VACCINES')    kp_drugs['SUBSTANCENAME'] = kp_drugs['desc'].str.replace('_', ';').astype(str)    kp_drugs.rename(columns={'code': 'PRODUCTNDC'}, inplace=True)    kp_atc_set = get_atc_ndc_map(kp_drugs[['PRODUCTNDC', 'SUBSTANCENAME']], onto_folder)    kp_atc_set['set'] = 'SET'    write_tsv(kp_atc_set[['set', 'atc', 'PRODUCTNDC']], dict_path, set_file, mode='a')if __name__ == '__main__':    #create_demo_dict()    #create_labs_dicts()    create_visit_adm_dicts()    #create_behav_dict()    #create_diagnosis_dict()    #copy_onto_files()    #create_drug_dict_with_atc_map()    #create_vaccination_dict()    # create_smoking_dict()    # create_tier_dict()